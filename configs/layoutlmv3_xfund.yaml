experiment_name: "layoutlmv3_xfund_zh"

# Dataset configuration
dataset:
  name: "xfund"
  hf_dataset_name: "FrancophonIA/XFUND"
  language: "zh"  # Chinese, can be changed to "ja", "es", "fr", "it", "de", "pt"
  task_type: "token_classification"
  preprocessing:
    max_seq_length: 512
    max_position_embeddings: 1024
    image_size: [224, 224]
    apply_ocr: false
    normalize_bbox: true
    include_image: false  # LayoutLMv3 text-only mode

# Model configuration  
model:
  name: "layoutlmv3"
  model_type: "layoutlmv3-base"
  pretrained_model_name: "microsoft/layoutlmv3-base"
  config:
    num_labels: 7  # Same as FUNSD: B-HEADER, I-HEADER, B-QUESTION, I-QUESTION, B-ANSWER, I-ANSWER, O
    hidden_dropout_prob: 0.1
    attention_probs_dropout_prob: 0.1
    classifier_dropout: 0.1

# Training configuration
training:
  batch_size: 2
  gradient_accumulation_steps: 4
  num_epochs: 100
  learning_rate: 5.e-5
  weight_decay: 0.01
  warmup_ratio: 0.1
  optimizer: "adamw"
  scheduler: "linear"
  save_strategy: "epoch"
  evaluation_strategy: "epoch"
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: "eval_f1"
  greater_is_better: true
  early_stopping_patience: 10

# Data processing
data_processing:
  train_split: "train"
  test_split: "validation"  # XFUND uses validation as test set
  validation_split: 0.1
  shuffle_train: true
  seed: 42

# Continual Learning Strategy
cl_strategy:
  name: "none"

# Evaluation settings
evaluation:
  metrics: ["accuracy", "f1", "precision", "recall"]
  save_predictions: true
  compute_entity_level_f1: true

# Logging and output
output:
  log_level: "INFO"
  save_model: true
  save_tokenizer: true
  push_to_hub: false

# Neptune experiment tracking (optional)
neptune:
  use_neptune: false
  neptune_project: "your-workspace/cl4ie"
  neptune_api_token: null
  tags: ["layoutlmv3", "xfund", "information_extraction", "multilingual"]
