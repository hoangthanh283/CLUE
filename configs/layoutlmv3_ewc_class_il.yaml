experiment_name: "layoutlmv3_ewc_class_il"

dataset:
  name: "funsd"
  hf_dataset_name: "nielsr/funsd"
  task_type: "token_classification"
  preprocessing:
    max_seq_length: 512
    max_position_embeddings: 1024
    image_size: [224, 224]
    apply_ocr: false
    normalize_bbox: true
    include_image: false

model:
  name: "layoutlmv3"
  model_type: "layoutlmv3-base"
  pretrained_model_name: "microsoft/layoutlmv3-base"
  config:
    num_labels: 7
    hidden_dropout_prob: 0.1
    attention_probs_dropout_prob: 0.1
    classifier_dropout: 0.1

cl_setting: "class_il"

training:
  batch_size: 1
  gradient_accumulation_steps: 4
  num_epochs: 5  # Increased from 1 - critical for EWC to learn meaningful parameters
  learning_rate: 5.0e-5
  weight_decay: 0.01
  warmup_ratio: 0.1
  optimizer: "adamw"
  scheduler: "linear"
  save_strategy: null
  evaluation_strategy: "epoch"
  save_total_limit: 1
  load_best_model_at_end: true
  metric_for_best_model: "f1"
  greater_is_better: true
  early_stopping_patience: 3

data_processing:
  train_split: "train"
  test_split: "test"
  validation_split: 0.1
  shuffle_train: true
  seed: 42

cl_strategy:
  name: "ewc"
  ewc_lambda: 0.4  # Reduced from 1.0 to prevent penalty from dominating
  ewc_store_on_cpu: true
  ewc_max_fisher_batches: 500
  # Fisher computation improvements
  fisher_method: "empirical"  # "empirical" (default) or "true" 
  fisher_sampling_type: "true_labels"  # "true_labels" (default) or "predicted"
  fisher_sparsity: 0.0  # Disabled sparsification (was 0.9)
  # Memory optimization (keep existing values)
  param_chunk_size: 300
  ewc_cache_dir: "ewc_cache"

label_space:
  unified: false

tasks:
  - name: "funsd"
    dataset:
      name: "funsd"
      hf_dataset_name: "nielsr/funsd"
  - name: "cord"
    dataset:
      name: "cord"
      hf_dataset_name: "naver-clova-ix/cord-v2"
  - name: "sroie"
    dataset:
      name: "sroie"
      hf_dataset_name: "buthaya/sroie"
  - name: "wildreceipt"
    dataset:
      name: "wildreceipt"
      hf_dataset_name: "kaydee/wildreceipt"
  - name: "xfund_zh"
    dataset:
      name: "xfund"
      hf_dataset_name: "nnul/xfund-multilingual"
      language: "zh"

evaluation:
  metrics: ["accuracy", "f1", "precision", "recall"]
  save_predictions: false

output:
  log_level: "INFO"
  save_model: true
  save_tokenizer: true
  push_to_hub: false

neptune:
  use_neptune: false
  neptune_project: "your-workspace/cl4ie"
  neptune_api_token: null
  tags: ["layoutlmv3", "class_il", "ewc", "funsd", "cord", "sroie", "wildreceipt", "xfund"]
